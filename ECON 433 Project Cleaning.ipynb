{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning part only. Further analysis conducted in Stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning part 1: create new song ID with instances and flag first and last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d1022fa65a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#turn weekID to date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msongs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeekID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeekID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(songs.info())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   1849\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing._parse_dateabbr_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    567\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_cache_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mlocale_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TimeRE_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocale_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         if (_getlang() != locale_time.lang or\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtzname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlocale_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtzname\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             time.daylight != locale_time.daylight):\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_getlang\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_getlang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Figure out what the current language is set to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLocaleTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/locale.py\u001b[0m in \u001b[0;36mgetlocale\u001b[0;34m(category)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLC_ALL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m';'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocalename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category LC_ALL is not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_localename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/locale.py\u001b[0m in \u001b[0;36m_parse_localename\u001b[0;34m(localename)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \"\"\"\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'@'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Deal with locale modifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "songs = pd.read_csv('Hot Stuff.csv')\n",
    "\n",
    "#turn weekID to date\n",
    "songs.WeekID = pd.to_datetime(songs.WeekID)\n",
    "\n",
    "#print(songs.info())\n",
    "songs_trunc = songs.sort_values(by = ['SongID', 'Instance', 'Weeks on Chart'])\n",
    "\n",
    "#creating songid_2\n",
    "new = songs_trunc['Instance'].astype(str).copy()\n",
    "#print (songs_trunc.info())\n",
    "songs_trunc['SongID_2'] = songs_trunc['SongID'].str.cat(new, sep = \" \")\n",
    "#print(songs_trunc['SongID_2'])\n",
    "\n",
    "#creating flag for first and last occurence (takes into account instances)\n",
    "songs_trunc['flag'] = ((songs_trunc.SongID_2 != songs_trunc.SongID_2.shift()) |\n",
    "                                             (songs_trunc.SongID_2 != songs_trunc.SongID_2.shift(-1))).astype(int)\n",
    "#only save flag = 1 to a csv\n",
    "songs_cleanish = songs_trunc.loc[songs_trunc.flag == 1, :]\n",
    "songs_cleanish.to_csv('songs_cleanish_2.csv')\n",
    "\n",
    "\n",
    "'''Testing: \n",
    "songs_clean = songs.sort_values('SongID', 'Instance', 'Weeks On Chart')\n",
    "songs_sort_sub = songs_sort.iloc[320000:320494,:]\n",
    "#songs_sort_sub.to_csv('last subset.csv')\n",
    "week1228 = songs_sort.loc[songs_sort.WeekID == datetime(2019,12,28), :]\n",
    "#print(week1228)\n",
    "week1221 = songs_sort.loc[songs_sort.WeekID == datetime(2019,12,21),:]\n",
    "#print(week1221)\n",
    "#print(songs_sort.iloc[320400:320494,:])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning part 2: create debut_week in accordane for each row to be used for survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint 1\n",
    "songs = pd.read_csv('songs_cleanish_2.csv')\n",
    "\n",
    "print(songs.info())\n",
    "print(songs.describe())\n",
    "\n",
    "#flag the last row for every instance\n",
    "songs['flag_last'] = ((songs.SongID_2 != songs.SongID_2.shift(-1))).astype(int)\n",
    "\n",
    "\n",
    "#Create debut_week and debut_position conditions\n",
    "# ['WeekID'] of flag = 0 --> ['Debut Week'] for index + 1\n",
    "# ['Week Postion'] of flag = 0 --> ['Debut Position'] for index + 1\n",
    "\n",
    "cond1 = songs['flag_last'] == songs['flag']\n",
    "cond2 = songs['flag_last'] != songs['flag_last'].shift()\n",
    "cond3 = songs['flag_last'] == songs['flag_last'].shift()\n",
    "\n",
    "\n",
    "#Make debut_week and debut_position\n",
    "songs['Debut_Week_2'] = np.where((cond1) & (cond2),\n",
    "            songs['WeekID'].shift(),\n",
    "            np.NaN)\n",
    "songs['Debut_Week_3'] = np.where(cond3,\n",
    "            songs['WeekID'],\n",
    "            np.NaN)\n",
    "songs['Debut_Position_2'] = np.where((cond1) & (cond2),\n",
    "            songs['Week Position'].shift(),\n",
    "            np.NaN)\n",
    "songs['Debut_Position_3'] = np.where(cond3,\n",
    "            songs['Week Position'],\n",
    "            np.NaN)\n",
    "\n",
    "'''Testing: \n",
    "songs['flag_temp_check'] = ((songs.Debut_Week == songs.Debut_Week.shift())).astype(int)\n",
    "print(songs.flag_temp_check.sum())'''\n",
    "\n",
    "print(songs)\n",
    "\n",
    "songs.to_csv('songs_cleanish_4.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning part 3: consolidate debut_week, take care of right censoring, create month and year for later manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint 2\n",
    "songs = pd.read_csv('songs_cleanish_4.csv')\n",
    "\n",
    "#subset to only last distinct entry\n",
    "songs_sub = songs.loc[songs['flag_last'] == 1, :]\n",
    "print(songs_sub.info())\n",
    "\n",
    "#combining columns for debut_week and debut_position\n",
    "songs_sub['Debut_Week_2'].fillna(songs_sub['Debut_Week_3'], inplace = True)\n",
    "songs_sub['Debut_Position_2'].fillna(songs_sub['Debut_Position_3'], inplace = True)\n",
    "\n",
    "songs_sub.drop(columns = ['Previous Week Position', 'Debut_Week_3', 'Debut_Week', 'Debut_Position', 'Debut_Position_3'], inplace = True)\n",
    "\n",
    "songs_sub.rename(columns={'Debut_Week_2':'Debut_Week',\n",
    "                          'Debut_Position_2':'Debut_Position'},\n",
    "                 inplace=True)\n",
    "\n",
    "#plot weeks on chart to check Weibull distribution\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = songs_sub['Weeks on Chart'].plot.hist(bins = 50)\n",
    "plt.show()\n",
    "\n",
    "#right censoring, get rid of any weeks that have a last flag at week28 (12-28-2019)\n",
    "print(songs_sub.info())\n",
    "songs_sub = songs_sub.sort_values(by = 'WeekID')\n",
    "songs_sub = songs_sub.reset_index(drop = True)\n",
    "\n",
    "week28 = songs_sub.at[30797, 'WeekID']\n",
    "'''Testing: print(week28)'''\n",
    "songs_sub_2 = songs_sub.loc[songs_sub.WeekID != week28, :]\n",
    "print(songs_sub_2.info())\n",
    "\n",
    "#add Month and year for Debut week for controls later\n",
    "songs_sub_2.Debut_Week = pd.to_datetime(songs_sub_2.Debut_Week)\n",
    "songs_sub_2['Month'] = songs_sub_2['Debut_Week'].dt.strftime('%m')\n",
    "songs_sub_2['Year'] = songs_sub_2['Debut_Week'].dt.strftime('%Y')\n",
    "print(songs_sub_2.info())\n",
    "\n",
    "#famous variable - debut position should control for fame/marketing?\n",
    "#songs_sub_2.sort_values(by = ['Performer', 'Song'])\n",
    "\n",
    "songs_sub_2.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'], inplace = True)\n",
    "#print(songs_sub_2.info())\n",
    "songs_sub_2.to_csv('songs_cleanish_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning part 4: merging datasets, cleaning up extraneous variables for import into Stata and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('songs_cleanish_5.csv')\n",
    "keywords_sent = pd.read_csv('lyric-keywords-sent.csv')\n",
    "aud_features = pd.read_excel('Hot 100 Audio Features.xlsx')\n",
    "lyrics = pd.read_csv('lyric-full_df.csv')\n",
    "\n",
    "#import unemployment data and change to ints\n",
    "unemployment = pd.read_csv('UNRATE.csv')\n",
    "unemployment.DATE = pd.to_datetime(unemployment.DATE)\n",
    "unemployment['Month'] = unemployment['DATE'].dt.strftime('%m').astype(int)\n",
    "unemployment['Year'] = unemployment['DATE'].dt.strftime('%Y').astype(int)\n",
    "\n",
    "print(songs.info())\n",
    "print(lyrics.info())\n",
    "print(keywords_sent)\n",
    "print(aud_features.info())\n",
    "\n",
    "songs.WeekID = pd.to_datetime(songs.WeekID)\n",
    "\n",
    "#chose to implement later/in stata\n",
    "''''Indicator variables after 2000: recession and unemployment\n",
    "cond1 = songs['WeekID'] >= datetime(2007, 12, 1)\n",
    "cond2 = songs['WeekID'] <= datetime(2009, 5, 1)\n",
    "cond3 = songs['WeekID'] >= datetime(2009, 4, 1)\n",
    "cond4 = songs['WeekID'] <= datetime(2011, 8, 1)\n",
    "songs['Recession'] = np.where(cond1 & cond2, 1, 0)\n",
    "songs['Unemploy'] = np.where(cond3 & cond4, 1, 0)\n",
    "'''\n",
    "\n",
    "#merge with unemployment data\n",
    "songs_unemploy = pd.merge(songs, unemployment[['Month','Year', 'UNRATE']],\n",
    "                          on = ['Month', 'Year'],\n",
    "                          how = 'left',\n",
    "                          left_index=True)\n",
    "\n",
    "#merge with sentiment analysis, kept lyrics just in case for further NPL\n",
    "songs_lyrics = pd.merge(songs_unemploy,\n",
    "                        lyrics[['SongID','Lyrics', 'Sentiment']],\n",
    "                        on = 'SongID',\n",
    "                        how = 'left',\n",
    "                        left_index = True)\n",
    "\n",
    "#merge with Spotify audio features\n",
    "songs_all = pd.merge(songs_lyrics,\n",
    "                     aud_features[['SongID','spotify_genre','spotify_track_duration_ms','mode', 'valence', 'tempo',\n",
    "                                   'danceability','energy','speechiness', 'acousticness','loudness', 'key']],\n",
    "                     on = 'SongID',\n",
    "                     how = 'left',\n",
    "                     left_index = True)\n",
    "\n",
    "#clean up\n",
    "songs_all.drop(columns='Unnamed: 0', inplace=True)\n",
    "print(songs_all.info())\n",
    "songs_all = songs_all.drop_duplicates(keep='first')\n",
    "print(songs_all.info())\n",
    "\n",
    "#plot and check distribution\n",
    "songs_all.sort_values(by = 'Weeks on Chart')\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "songs_all['survival'] = np.log(songs_all['Weeks on Chart'])\n",
    "ax = songs_all['survival'].plot.hist(bins = 50)\n",
    "ax = songs_all['Weeks on Chart'].plot.hist(bins = 50)\n",
    "plt.show()\n",
    "\n",
    "#clean up for import into stata and SQL (no strings with commas)\n",
    "songs_all.drop(columns=['Lyrics', 'spotify_genre'], inplace=True)\n",
    "songs_all = songs_all.reset_index(drop = True)\n",
    "\n",
    "print(songs_all.size)\n",
    "songs_all.to_csv('songs_all_2.csv')\n",
    "\n",
    "#notes:\n",
    "#lyrics goes up to 2019-06-22\n",
    "#songs_all_2 = songs_all.reset_index().drop_duplicates(subset='index',\n",
    "                                 #      keep='first').set_index('index')\n",
    "'''Testing: \n",
    "nullsongs = songs_all_2[songs_all_2.isna().any()]\n",
    "print(nullsongs.info())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('songs_all_2.csv')\n",
    "print(songs.shape)\n",
    "songs = songs.sort_values(by = ['SongID', 'Instance'])\n",
    "songs = songs.reset_index(drop = True)\n",
    "\n",
    "#Weeks substracted for instances\n",
    "cond1 = songs['Instance'] > songs['Instance'].shift()\n",
    "songs['WeekChart2'] = np.where((cond1),\n",
    "            songs['Weeks on Chart']-songs['Weeks on Chart'].shift(),\n",
    "            songs['Weeks on Chart'])\n",
    "'''Testing: songs.survival = np.log(songs.WeekChart2)\n",
    "songs['WeekChart2'].plot.hist(bins = 100)\n",
    "songs['survival'].plot.hist(bins = 50)\n",
    "plt.show()'''\n",
    "\n",
    "#setting recession indicator\n",
    "songs.Debut_Week = pd.to_datetime((songs.Debut_Week))\n",
    "#print(songs.info())\n",
    "cond1 = (songs.Debut_Week > ('1960-04-01')) & (songs.Debut_Week < ('1961-02-01'))\n",
    "cond2 = (songs.Debut_Week > ('1970-01-01')) & (songs.Debut_Week < ('1970-11-01'))\n",
    "cond3 = (songs.Debut_Week > datetime(1973,12,1)) & (songs.Debut_Week < datetime(1975, 2,1))\n",
    "cond4 = (songs.Debut_Week > datetime(1980,1,1)) & (songs.Debut_Week < datetime(1980, 5,1))\n",
    "cond5 = (songs.Debut_Week > datetime(1981,8,1)) & (songs.Debut_Week < datetime(1982, 11,1))\n",
    "cond6 = (songs.Debut_Week > datetime(1990,8,1)) & (songs.Debut_Week < datetime(1991, 3,1))\n",
    "mask = (cond1 | cond2 | cond3 | cond4 | cond5 | cond6)\n",
    "songs['recession'] = np.where(mask, 1, 0)\n",
    "\n",
    "#export\n",
    "songs.to_csv('songs_all_3_2.csv')\n",
    "\n",
    "#restrict sample to before 1992 only due to week20 abnormality after 1992\n",
    "songs_temp = songs.loc[songs.WeekID < datetime(1992, 1, 1), :]\n",
    "print(songs_temp)\n",
    "songs_temp.to_csv('songs_before_1992.csv')\n",
    "\n",
    "'''Testing: print(songs.loc[songs.Song =='22', :])\n",
    "songs_temp.WeekChart2.plot.hist(bins = 80)\n",
    "plt.show()\n",
    "songs.WeekChart2.plot.hist(bins = 100)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#taking out instances\n",
    "songs = pd.read_csv('songs_all_2.csv')\n",
    "songs = songs.sort_values(by = ['SongID', 'Instance'])\n",
    "songs = songs.reset_index(drop = True)\n",
    "\n",
    "cond2 = songs['Peak Position'] > songs['Peak Position'].shift()\n",
    "cond3 = songs['Song'] == songs['Song'].shift()\n",
    "\n",
    "songs['Peak'] = np.where((cond2) & (cond3),\n",
    "                         songs['Peak Position'].shift(),\n",
    "                         songs['Peak Position'])\n",
    "\n",
    "print(songs.shape)\n",
    "songs = songs.sort_values(by = ['SongID', 'Instance'])\n",
    "songs.flag_last = ((songs.SongID != songs.SongID.shift(-1))).astype(int)\n",
    "songs = songs.loc[songs.flag_last == 1, :]\n",
    "\n",
    "#export various\n",
    "songs.to_csv('songs_all_without_instances.csv')\n",
    "\n",
    "songs.WeekID = pd.to_datetime(songs.WeekID)\n",
    "songs_before = songs.loc[songs.WeekID < datetime(1992, 1, 1), :]\n",
    "songs_before.to_csv('songs_before_1992 without_instances.csv')\n",
    "\n",
    "songs_before = songs_before.loc[songs['Peak'] <= 10, :]\n",
    "songs_before.to_csv('top10_songs_before_1992_without_instances.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
